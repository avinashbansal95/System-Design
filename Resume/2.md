Engineered and deployed scalable microservices using Node.js on AWS, enhancing system performance and supporting
increased user traffic, resulting in a 30 percent improvement in response times and the ability to handle up to million
requests per minute.


# Performance Monitoring Queries Guide

## New Relic (NRQL) — Example Queries

### Average Duration for a Service
```nrql
SELECT average(duration) FROM Transaction 
WHERE appName = 'MyApp' 
SINCE '2025-08-01 10:00:00' 
UNTIL '2025-08-01 12:00:00'
```

### P95 Duration (Recommended)
```nrql
SELECT percentile(duration, 95) FROM Transaction 
WHERE appName = 'MyApp' 
SINCE 2 hours ago 
UNTIL now
```

**Note:** To show before/after, run the same percentile query for the two windows and compute percent change outside NR (or use two NRQL queries and compare visually).

## CloudWatch — Using ALB Metric or Custom Metric

### ALB Target Response Time
- **Metric:** `AWS/ApplicationELB -> TargetResponseTime`
- **Statistics:** Use `p50` or `p95` in CloudWatch Metrics

### Metric Math Example
In CloudWatch metric math:
- Let `m1` = baseline p95
- Let `m2` = after p95
- **Expression to compute percent improvement:** `((m1 - m2) / m1) * 100`

### CloudWatch Logs Insights
If you log latency as `latencyMs`:

```sql
fields @timestamp, latencyMs
| filter @timestamp >= '2025-08-01T10:00:00Z' and @timestamp < '2025-08-01T12:00:00Z'
| stats avg(latencyMs) as avgLat, pct(latencyMs, 95) as p95Lat
```

**Usage:** Run that for baseline and post-deploy windows and compute percent change.


They’re percentiles of response time distribution.
Instead of just looking at the average latency, percentiles show how latency is distributed across all requests.

p50 latency (median):

50% of requests are faster than this, 50% are slower.

Example: if p50 = 100 ms, half your requests finished within 100 ms.

p95 latency:

95% of requests are faster, 5% are slower.

Example: if p95 = 300 ms, most requests are fast, but the slowest 5% take longer than 300 ms.

This shows the “tail latency” that real users notice when some requests lag.

p99 latency:

99% of requests are faster, only 1% are slower.

Example: if p99 = 1,000 ms, that means 1% of requests took longer than 1 second.

This highlights rare but painful slow requests.

-- Before deploy
SELECT percentile(duration, 95)
FROM Transaction
WHERE appName = 'MyApp'
  AND name = 'WebTransaction/Expressjs/GET//api/v1/users/:id'
SINCE '2025-09-14 08:00:00' UNTIL '2025-09-14 10:00:00';

-- After deploy
SELECT percentile(duration, 95)
FROM Transaction
WHERE appName = 'MyApp'
  AND name = 'WebTransaction/Expressjs/GET//api/v1/users/:id'
SINCE '2025-09-14 10:05:00' UNTIL '2025-09-14 12:05:00';
Use identical duration windows (same length, similar traffic patterns). Then compute percent change:

ini
Copy code
percent_improvement = ((before_p95 - after_p95) / before_p95) * 100
B — Use NRQL COMPARE WITH (quick visual compare)
NRQL can compare the current window with a previous equal-length window automatically:

sql
Copy code
SELECT percentile(duration, 95)
FROM Transaction
WHERE appName = 'MyApp'
  AND name LIKE '%/api/v1/users%'
SINCE 2 hours ago
COMPARE WITH 2 hours ago